{"cells":[{"cell_type":"markdown","source":["# Klasyfikacja tekstów sieciami neuronowymi"],"metadata":{"id":"Vo_IetBwn-mi"}},{"cell_type":"markdown","source":["Ten plik pozwala na seryjne testowanie klasyfikatorów i pozyskanie wyników (w formacie tabeli latexowych, macierzy pomyłek) dla określonych zbiorów zapisanych w formacie pickle. Uruchomienie wszsytkich komórek z notatnika powoduje wygenerowanie wyników dla wszystkich okreśonych zbiorów zapamiętanych w formacie pickle."],"metadata":{"id":"IlzyJJoHobfp"}},{"cell_type":"markdown","source":["### Działania przygotowawcze: podłączenie Dysku Google, instalacja wymaganych pakietów, dołączenie katalogu projektu do ścieżki systemowej i import potrzebnych klas z projektu"],"metadata":{"id":"kaPrlLTWopO0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19226,"status":"ok","timestamp":1687168500909,"user":{"displayName":"Gosia Maciejewska","userId":"08988235621772941797"},"user_tz":-120},"id":"z3y-Cr0OfmOr","outputId":"b430dfae-5a54-43cc-f910-d895d92dabec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/authorship_anaysis/authorship_analysis/training_models\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","# ścieżka do bieżącego katalogu (należy edytować, jeśli się nie zgadza)\n","%cd gdrive/MyDrive/praca_inzynierska/authorship_analysis_project/training_models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148056,"status":"ok","timestamp":1687168654428,"user":{"displayName":"Gosia Maciejewska","userId":"08988235621772941797"},"user_tz":-120},"id":"DxIQyDq8fnJX","outputId":"95f872fe-06ed-4594-c8de-476f59d853ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting https://github.com/kpu/kenlm/archive/master.zip (from -r ../requrements.txt (line 9))\n","  Downloading https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.5/553.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting langid (from -r ../requrements.txt (line 1))\n","  Downloading langid-1.1.6.tar.gz (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r ../requrements.txt (line 2)) (1.2.2)\n","Collecting lime (from -r ../requrements.txt (line 3))\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting shap (from -r ../requrements.txt (line 4))\n","  Downloading shap-0.41.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.6/572.6 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r ../requrements.txt (line 5)) (0.12.2)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from -r ../requrements.txt (line 6)) (2.12.0)\n","Collecting transformers (from -r ../requrements.txt (line 7))\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from -r ../requrements.txt (line 8)) (0.20.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from langid->-r ../requrements.txt (line 1)) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r ../requrements.txt (line 2)) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r ../requrements.txt (line 2)) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r ../requrements.txt (line 2)) (3.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime->-r ../requrements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime->-r ../requrements.txt (line 3)) (4.65.0)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime->-r ../requrements.txt (line 3)) (0.19.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap->-r ../requrements.txt (line 4)) (1.5.3)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap->-r ../requrements.txt (line 4)) (23.1)\n","Collecting slicer==0.0.7 (from shap->-r ../requrements.txt (line 4))\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap->-r ../requrements.txt (line 4)) (0.56.4)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap->-r ../requrements.txt (line 4)) (2.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r ../requrements.txt (line 7)) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers->-r ../requrements.txt (line 7))\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ../requrements.txt (line 7)) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ../requrements.txt (line 7)) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r ../requrements.txt (line 7)) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r ../requrements.txt (line 7))\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r ../requrements.txt (line 7))\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->-r ../requrements.txt (line 7)) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->-r ../requrements.txt (line 7)) (4.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->-r ../requrements.txt (line 3)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->-r ../requrements.txt (line 3)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->-r ../requrements.txt (line 3)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->-r ../requrements.txt (line 3)) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->-r ../requrements.txt (line 3)) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->-r ../requrements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->-r ../requrements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap->-r ../requrements.txt (line 4)) (2022.7.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->-r ../requrements.txt (line 3)) (3.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->-r ../requrements.txt (line 3)) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->-r ../requrements.txt (line 3)) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->-r ../requrements.txt (line 3)) (1.4.1)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap->-r ../requrements.txt (line 4)) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap->-r ../requrements.txt (line 4)) (67.7.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r ../requrements.txt (line 7)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r ../requrements.txt (line 7)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r ../requrements.txt (line 7)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r ../requrements.txt (line 7)) (3.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime->-r ../requrements.txt (line 3)) (1.16.0)\n","Building wheels for collected packages: langid, lime, kenlm\n","  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=7552f74ef89610be9b4a66363621bb58163bd947f976c5b72caffd49c762bd5a\n","  Stored in directory: /root/.cache/pip/wheels/23/c8/c6/eed80894918490a175677414d40bd7c851413bbe03d4856c3c\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283839 sha256=3637d966455a09ae877f5e5d763e7a22e9e70569c9e38799e08bc59bdd77bd35\n","  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n","  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kenlm: filename=kenlm-0.0.0-cp310-cp310-linux_x86_64.whl size=3255392 sha256=50b56bc30283aadb90140477e3f25a892704a16871e5558b73deebd4047e5719\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-26gw6wxb/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n","Successfully built langid lime kenlm\n","Installing collected packages: tokenizers, safetensors, kenlm, slicer, langid, huggingface-hub, transformers, shap, lime\n","Successfully installed huggingface-hub-0.15.1 kenlm-0.0.0 langid-1.1.6 lime-0.2.0.1 safetensors-0.3.1 shap-0.41.0 slicer-0.0.7 tokenizers-0.13.3 transformers-4.30.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting https://github.com/kpu/kenlm/archive/master.zip\n","  Using cached https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","2023-06-19 09:57:00.684235: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-19 09:57:01.708324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-06-19 09:57:03.130779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-06-19 09:57:03.131384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-06-19 09:57:03.131627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pl-core-news-lg==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_lg-3.5.0/pl_core_news_lg-3.5.0-py3-none-any.whl (573.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.7/573.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from pl-core-news-lg==3.5.0) (3.5.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (8.1.9)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (1.1.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (2.4.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (2.0.8)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (0.7.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (0.10.1)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (6.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (4.65.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (1.22.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (2.27.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (1.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (3.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->pl-core-news-lg==3.5.0) (2.1.2)\n","Installing collected packages: pl-core-news-lg\n","Successfully installed pl-core-news-lg-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('pl_core_news_lg')\n"]}],"source":["! pip install -r ../requrements.txt\n","! pip install https://github.com/kpu/kenlm/archive/master.zip\n","! python -m spacy download pl_core_news_lg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1684882935536,"user":{"displayName":"Gosia Maciejewska","userId":"08988235621772941797"},"user_tz":-120},"id":"IUoxUsQne5ok","outputId":"29cee4da-9814-4873-fca7-bc3596554efc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/authorship_anaysis/authorship_analysis\n","['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython', '/content/gdrive/MyDrive/authorship_anaysis/authorship_analysis']\n"]}],"source":["import os\n","import sys\n","module_path = os.path.abspath(os.path.join('..'))\n","if module_path not in sys.path:\n","    sys.path.append(module_path)\n","print(module_path)\n","print(sys.path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15605,"status":"ok","timestamp":1684882951127,"user":{"displayName":"Gosia Maciejewska","userId":"08988235621772941797"},"user_tz":-120},"id":"OYqTghXWe5oo","outputId":"d03fdbcb-41ee-4d5a-e446-62fe7e582d5e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn(\n"]}],"source":["from data_preparation import CorpusPreparation\n","from pipelines import Pipeline, Explain\n","from data_fetchers import EpochsFetcher, BookSet"]},{"cell_type":"markdown","source":["### Zbiory treningowe i testowe"],"metadata":{"id":"fD7G7f6rowz4"}},{"cell_type":"markdown","source":["Lista dostępnych zbiorów zapisanych jako pickle. Zbiory oznaczone są liczbami naturalnymi i cyfra dziesiątek oznacza sposób podziału zbioru na zbiory testowe i uczące z określoną liczbą słów w próbce, a cyfra jednosci oznacza wybrany preprocessing."],"metadata":{"id":"UebWjRXZow3U"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3996,"status":"ok","timestamp":1684882955108,"user":{"displayName":"Gosia Maciejewska","userId":"08988235621772941797"},"user_tz":-120},"id":"Yt7JMm5NiGVI","outputId":"15c25a95-41f2-423a-8bfa-438c4247cf04"},"outputs":[{"name":"stdout","output_type":"stream","text":["datasets/features_0\n","test_size: 20, train_size: 100, number of words in paragraph: 15, preprocessing operations: ['anonymize'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_1\n","test_size: 20, train_size: 100, number of words in paragraph: 15, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_2\n","test_size: 20, train_size: 100, number of words in paragraph: 15, preprocessing operations: ['anonymize'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_3\n","test_size: 20, train_size: 100, number of words in paragraph: 15, preprocessing operations: ['anonymize', 'lower_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_5\n","test_size: 20, train_size: 100, number of words in paragraph: 15, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only', 'lemmatize_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_6\n","test_size: 16, train_size: 80, number of words in paragraph: 30, preprocessing operations: ['anonymize'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_10\n","test_size: 10, train_size: 50, number of words in paragraph: 30, preprocessing operations: ['anonymize'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_11\n","test_size: 10, train_size: 50, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_12\n","test_size: 10, train_size: 50, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_13\n","test_size: 10, train_size: 50, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_14\n","test_size: 10, train_size: 48, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_15\n","test_size: 10, train_size: 48, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only', 'lemmatize_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_20\n","test_size: 40, train_size: 200, number of words in paragraph: 50, preprocessing operations: ['anonymize'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_21\n","test_size: 40, train_size: 200, number of words in paragraph: 50, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_22\n","test_size: 40, train_size: 200, number of words in paragraph: 50, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_23\n","test_size: 40, train_size: 200, number of words in paragraph: 50, preprocessing operations: ['anonymize', 'lower_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_25\n","test_size: 40, train_size: 200, number of words in paragraph: 50, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only', 'lemmatize_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_30\n","test_size: 20, train_size: 100, number of words in paragraph: 100, preprocessing operations: ['anonymize'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_31\n","test_size: 20, train_size: 100, number of words in paragraph: 100, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_32\n","test_size: 20, train_size: 100, number of words in paragraph: 100, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_33\n","test_size: 20, train_size: 100, number of words in paragraph: 100, preprocessing operations: ['anonymize', 'lower_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_35\n","test_size: 20, train_size: 100, number of words in paragraph: 100, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only', 'lemmatize_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_40\n","test_size: 60, train_size: 300, number of words in paragraph: 30, preprocessing operations: ['anonymize'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_41\n","test_size: 60, train_size: 300, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_42\n","test_size: 60, train_size: 300, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_43\n","test_size: 60, train_size: 300, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_45\n","test_size: 60, train_size: 300, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only', 'lemmatize_text', 'remove_punctuation'], authors: ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","datasets/features_50\n","test_size: 400, train_size: 1000, number of words in paragraph: 30, preprocessing operations: ['anonymize'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_51\n","test_size: 400, train_size: 1000, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_52\n","test_size: 400, train_size: 1000, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_53\n","test_size: 400, train_size: 1000, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_54\n","test_size: 400, train_size: 1000, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_55\n","test_size: 400, train_size: 1000, number of words in paragraph: 30, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only', 'lemmatize_text', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_60\n","test_size: 400, train_size: 1000, number of words in paragraph: 300, preprocessing operations: ['anonymize'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_61\n","test_size: 400, train_size: 1000, number of words in paragraph: 300, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_62\n","test_size: 400, train_size: 1000, number of words in paragraph: 300, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_63\n","test_size: 400, train_size: 1000, number of words in paragraph: 300, preprocessing operations: ['anonymize', 'lower_text', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_64\n","test_size: 400, train_size: 1000, number of words in paragraph: 300, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_65\n","test_size: 400, train_size: 1000, number of words in paragraph: 300, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only', 'lemmatize_text', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_70\n","test_size: 120, train_size: 300, number of words in paragraph: 1000, preprocessing operations: ['anonymize'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_71\n","test_size: 120, train_size: 300, number of words in paragraph: 1000, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_72\n","test_size: 120, train_size: 300, number of words in paragraph: 1000, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_73\n","test_size: 120, train_size: 300, number of words in paragraph: 1000, preprocessing operations: ['anonymize', 'lower_text', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_74\n","test_size: 120, train_size: 300, number of words in paragraph: 1000, preprocessing operations: ['anonymize', 'lower_text', 'remove_stop_words', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n","datasets/features_75\n","test_size: 120, train_size: 300, number of words in paragraph: 1000, preprocessing operations: ['anonymize', 'lower_text', 'POS_leave_only', 'lemmatize_text', 'remove_punctuation'], authors: ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']\n"]}],"source":["import pickle\n","from os.path import exists\n","datasets_filepath = 'datasets/features_'\n","for i in range(100):\n","  path = datasets_filepath + str(i)\n","  if exists(path):\n","    print(path)\n","    with open(path, 'rb') as f:\n","      data = pickle.load(f)\n","      head_data, _, _, _, _ = data\n","      print(f'test_size: {head_data[0]}, train_size: {head_data[1]}, number of words in paragraph: {head_data[2]}, preprocessing operations: {head_data[3]}, authors: {head_data[4]}')"]},{"cell_type":"markdown","source":["### Określenie rodzajów preprocessingu i wybór zbiorów, deklaracja zmiennych"],"metadata":{"id":"NCkI8P_NqEty"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MymqlvwAe5oq"},"outputs":[],"source":["preps_num = [0,1,2,3,5] # wybór preprocessingu\n","preps_descr = ['a', 'als', 'alo_NVAdj', 'alp', 'alsp', 'alomp_NVAdj']\n","div_num= [5,6,7] #[0,1,2,3,4,5,6,7] # wybór numeru podziału zbioru z wielkością próbki\n","number_of_dataset = 11\n","\n","mixed = None\n","test_size = None\n","train_size = None\n","words_num_in_par = None\n","representations = ['emb'] #'bow'/ 'wp'/ 'emb'\n","models= ['nn']\n","layers_arch = 'embed_basic' # 'basic', 'lstm', 'embed_basic', 'embed_glove_lstm'\n","authors = []\n","preprocessing_list = []\n","train_classes = []\n","prep_descr = ''\n","kinds_descr = ''\n","latex_set_str = ''\n"]},{"cell_type":"markdown","source":["### Definicje funkcji"],"metadata":{"id":"5LtcxlV3rIJk"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vSiF_WqRcMV-"},"outputs":[],"source":["def get_books_epoch_list():\n","  print(authors)\n","  bookset = BookSet()\n","  bookset.fetch()\n","  if authors == ['Eliza Orzeszkowa', 'Henryk Sienkiewicz', 'Bolesław Prus']:\n","    kinds =['Epika']\n","    books_list = bookset.list_of_books_to_author_title_list(bookset.get_books_by_authors_list_kinds(authors, kinds))\n","    books_epoch_list = [books_list]\n","  if authors == ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka', 'Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid', 'Adam Asnyk', 'Maria Konopnicka', 'Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']:\n","    kinds = ['Liryka']\n","    authors_b = ['Daniel Naborowski', 'Mikołaj Sęp Szarzyński', 'Elżbieta Drużbacka']\n","    authors_r = ['Adam Mickiewicz', 'Juliusz Słowacki', 'Cyprian Kamil Norwid']\n","    authors_p = ['Adam Asnyk', 'Maria Konopnicka']\n","    authors_m = ['Kazimierz Przerwa-Tetmajer', 'Bolesław Leśmian', 'Jan Kasprowicz']\n","    books_list_b = bookset.list_of_books_to_author_title_list(bookset.get_books_by_authors_list_kinds(authors_b, kinds))\n","    books_list_r = bookset.list_of_books_to_author_title_list(bookset.get_books_by_authors_list_kinds(authors_r, kinds))\n","    books_list_p = bookset.list_of_books_to_author_title_list(bookset.get_books_by_authors_list_kinds(authors_p, kinds))\n","    books_list_m = bookset.list_of_books_to_author_title_list(bookset.get_books_by_authors_list_kinds(authors_m, kinds))\n","    books_epoch_list = [books_list_b, books_list_r, books_list_p, books_list_m]\n","  return books_epoch_list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"R-QMNeeQe5or"},"outputs":[],"source":["def get_existing_authors():\n","  existing_authors_set = set(train_classes)\n","  #print(existing_authors_set)\n","  authors_max_books = {}\n","  authors_ = []\n","  books_epoch_list = get_books_epoch_list()\n","  #print(books_epoch_list)\n","  for books_epoch in books_epoch_list:\n","      authors_list = [author for (author, title) in books_epoch]\n","      authors_set = sorted(list(set(authors_list)))\n","      for author in authors_set:\n","          if author in existing_authors_set:\n","              books_num = authors_list.count(author)\n","              if author in authors_:\n","                  if books_num > authors_max_books[author]:\n","                      authors_.remove(author)\n","                      authors_max_books[author] = books_num\n","                      authors_.append(author)\n","              else:\n","                  authors_.append(author)\n","                  authors_max_books[author] = books_num\n","  return authors_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qgMfrFz7Ty4o"},"outputs":[],"source":["def conf_path():\n","  div = ''\n","  if not mixed:\n","      div = '_div'\n","  path = f'../figures/aut_nn_x_fig_{layers_arch}_{train_size}_{test_size}_{words_num_in_par}{div}_{prep_descr}_{kinds_descr}.jpg'\n","  return path\n","\n","def get_latex_set_str(p: int, d: int):\n","  prep = preps_descr[p].partition('_')[0].upper()\n","  if d < 2:\n","    st = 'Y'\n","  elif d < 5:\n","    st = \"Y'\"\n","  else:\n","    st = 'X'\n","  return '$' + chr(92) + 'mathbb{' + st + '}_{' + prep + '}$'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yBRUf6DJJA1o"},"outputs":[],"source":["def get_nn_args_dict():\n","  select_k_wp = 5000 # X 8000, Y' 5000, Y 1000\n","  select_k_bow = 5000 # X 8000, Y' 5000, Y 1000\n","  epochs_bow = 32\n","  epochs_wp = 32\n","  batch_size = 64\n","  layer_units = 64\n","\n","  ann_args_bow = [select_k_bow, epochs_bow, batch_size, layer_units, layers_arch]\n","  ann_args_wp = [select_k_wp, epochs_wp, batch_size, layer_units, layers_arch]\n","\n","  ann_args_dict = {\n","      (representations[0], models[0]): ann_args_bow\n","      #(representations[1], models[0]): ann_args_wp\n","  }\n","  return ann_args_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9X3KQy3bJ41F"},"outputs":[],"source":["def run_pipeline():\n","  authors_ = get_existing_authors()\n","  nn_args_dict = get_nn_args_dict()\n","  p = Pipeline(\n","    corpus_train=train_set,\n","    corpus_test=test_set,\n","    classes_train=train_classes,\n","    classes_test=test_classes,\n","    class_names=authors_,\n","    representations=representations,\n","    models=models,\n","    ann_args_dict=nn_args_dict)\n","  p.pipelines()\n","  p.accuracy_latex_format(f'../results/nn_{layers_arch}_x_table.tex', latex_set_str)\n","  p.save_img(conf_path())\n","  #expl = Explain(p)"]},{"cell_type":"markdown","source":["###Pętla klasyfikacji"],"metadata":{"id":"ljk5Takirtg0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1bA2NSMcEbJSU5m106oTiKfA6HIrm1b--"},"id":"YT-i_q2xOHN0","outputId":"a42d0d9c-d964-41ba-8b86-26a9a0ac8684"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["for p in preps_num:\n","  for d in div_num:\n","    number_of_dataset = str(d)+str(p) if d>0 else str(p)\n","    if d < 5:\n","      mixed = True\n","      kinds_descr = 'l'\n","    else:\n","      mixed = False\n","      kinds_descr = 'e'\n","    latex_set_str = get_latex_set_str(p,d)\n","    prep_descr = preps_descr[p]\n","    file_name_read = datasets_filepath + str(number_of_dataset)\n","    with open(file_name_read, 'rb') as f:\n","      data = pickle.load(f)\n","      head_data, train_set, train_classes, test_set, test_classes = data\n","      test_size, train_size, words_num_in_par, preprocessing_list, authors = head_data\n","    print(get_books_epoch_list())\n","    run_pipeline()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"env_python3_10","language":"python","name":"env_python3_10"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}